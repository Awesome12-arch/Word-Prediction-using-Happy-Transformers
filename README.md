# Word-Prediction-using-Happy-Transformers
Word prediction is a fundamental natural task for Transformer models. For example, BERT was pre-trained by using a combination of masked word prediction and next sentence prediction.
A deep understanding of language is required to complete it, making it an appealing choice for pre-training large language models.
We've made the use of Happy Transformer to implement and fine-tune word prediction models.
